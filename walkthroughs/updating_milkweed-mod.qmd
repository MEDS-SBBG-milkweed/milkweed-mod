# Intro


#### Load packages
```{r}
library(spocc)
library(spThin)
library(dismo)
library(sf)
library(ENMeval)
library(wallace)
library(tidyverse)
library(here)
library(terra)
library(raster)
source("R/addLegend_decreasing.R")
source("R/setup.R")
```


```{r}
# generating *fake* data to test the walk through- will be deleted ----
library(rgbif)
gbif_data <- occ_data(scientificName = "Asclepias eriocarpa", hasCoordinate = TRUE, limit = 400) 
new_data <- gbif_data$data %>%
  filter(stateProvince == "California",
         decimalLongitude < -121.0, 
         decimalLatitude < 37) %>%
  select(decimalLongitude, decimalLatitude, scientificName) %>%
  rename(longitude = decimalLongitude,
         latitude = decimalLatitude,
         milkweed_sp = scientificName) %>%
  mutate(milkweed_sp = "Asclepias eriocarpa",
         region = "North") %>%
  rename(scientific_name = milkweed_sp)

ggplot() +
  geom_point(data = new_data, aes(x = longitude, y = latitude), size = 0.5) +
  geom_sf(data = lpnf_north_buffered, alpha = 0.5)
```


#### Read in data used for modeling
```{r}
# environmental data raster stack
environmental_layers <- brick("path/to/env_stack.tif")
# environmental_layers <- envs_Ac

# los padres forest boundary files
lpnf_boundary <- st_read("path/to/lpnf_boundary.shp")
lpnf_north <- st_read("path/to/lpnf_boundary_north.shp")
lpnf_south <- st_read("path/to/lpnf_boundary_south.shp")

# read in properly formatted milkweed polygon data
milkweed_data_raw <- st_read("path/to/data")
# milkweed_data_raw <- st_read(here("~/../../capstone/milkweedmod/raw_data/milkweed_polygon_data/"))
```

##### Troubleshooting Errors
Problems with reading in the data:


# Species Distribution Model 
## Adding new data

### Clean new milkweed survey data
Now that the new data milkweed data is read in, we want to check that the structure of the data looks correct. Using `View(milkweed_data_raw)` look for the columns in the data `Milkweed_P`, `MilkweedSp`, `region`, and `geometry` (geometry will be the very last column). These are the columns we want to use for the species distribution modeling. 
```{r}
# view the data frame; the data frame will pop up in a new tab at the top
View(milkweed_data_raw)
```

##### Troubleshooting Errors
Different column names/missing columns:

### Clean New Data
If everything is looking good, let's move on to cleaning the data up a bit. We want to select only the columns we need for modeling, and rename them to names that are a bit simpler. Since this data has both "yes" and "no" values in the `Milkweed_P`, we want to filter to only keep the "yes" values. Finally, let's transform the coordinate reference system (CRS) to EPSG:4326, since this the the CRS that the prepared environmental data is in. 
```{r}
milkweed_clean <- milkweed_data_raw |> 
  janitor::clean_names() |> 
  filter(milkweed_p != "no")  %>%
  st_transform("EPSG:4326") %>%
  dplyr::select(milkweed_sp)

# check that the new clean data is looking correct
head(milkweed_clean)
```

Here's an example what the data structure should look like:
```
  milkweed_sp       geometry
1 Asclepias vestita MULTIPOLYGON (((-119.3003 3...
2 Asclepias erosa   MULTIPOLYGON (((-119.1852 3...
3 Asclepias cali... MULTIPOLYGON (((-119.402 34...
```

#### Convert Polygons to Points
Maxent modeling only works with point data, so we are going to use the multipolygon border to extract points from the area.

```{r}
# get the points from polygons
milkweed_cast_points <- st_cast(milkweed_clean, "MULTIPOINT") %>% 
  st_cast("POINT")
# here you will get a warning about sub-geometries, but that's okay

milkweed_points <- milkweed_cast_points %>%
  group_by(milkweed_sp) %>% 
  st_coordinates() %>% # get the lat long coords from the point geometries (this returns only the lat long as a list)
  data.frame() %>% # convert list to a data frame
  cbind(milkweed_cast_points) %>% # join the data frame of points with the casted geometry points to get the species 
  dplyr::select(-geometry) %>% # drop the casted geometry points (don't need since we have the lat long now)
  rename(longitude = X, # update names
         latitude = Y,
         scientific_name = milkweed_sp) %>% # in the function, the species column must be called 'scientific_name'
  mutate(occID = row_number())

head(milkweed_points)

# ---------------------
milkweed_points <- milkweed_cast_points %>%
  group_by(milkweed_sp) %>% 
  st_coordinates() %>% # get the lat long coords from the point geometries (this returns only the lat long as a list)
  data.frame() %>% # convert list to a data frame
  cbind(milkweed_cast_points) %>% # join the data frame of points with the casted geometry points to get the species 
  dplyr::select(-geometry) %>% # drop the casted geometry points (don't need since we have the lat long now)
  rename(longitude = X, # update names
         latitude = Y,
         scientific_name = milkweed_sp) %>%
  mutate(region = "South")
```

The head() of milkweed_points should look similar to this:
```
    longitude latitude       scientific_name occID
1   -119.9609 34.71440 Asclepias californica     1
1.1 -119.9610 34.71402 Asclepias californica     2
1.2 -119.9612 34.71343 Asclepias californica     3
```
*Note the index looks kind of weird (1, 1.1, 1.2 etc) since we split a polygon (one row) in to multiple row, which added the decimal steps. 


### Join new data with old data

If this new data is in the same data frame as the data originally used for modeling, **do not** run this next code chunk, and move on the the next section **Data Sub-setting**. If this new data has none of the previous survey data, continue with running the code below. 

```{r}
milkweed_points <- rbind(milkweed_points, milkweed_survey_2023) %>%
  mutate(occID = row_number())

# milkweed_points <- rbind(milkweed_points, new_data) %>%
#  mutate(occID = row_number())
```

##### Troubleshooting Errors


### Data subsetting

#### Select data for each species in the northern region of the LPNF
```{r}
# filter to only have data from the northern region 
milkweed_north <- milkweed_points %>%
  filter(region == "North")

# californica
californica_north <- milkweed_north %>%
  filter(scientific_name == "Asclepias californica")
# erosa
erosa_north <- milkweed_north %>%
  filter(scientific_name == "Asclepias erosa")
# eriocarpa
eriocarpa_north <- milkweed_north %>%
  filter(scientific_name == "Asclepias eriocarpa")
# vestita
vestita_north <- milkweed_north %>%
  filter(scientific_name == "Asclepias vestita")
```

#### Select data for each species in the southern region of the LPNF
```{r}
# filter to only have data from the southern region
milkweed_south <- milkweed_points %>%
  filter(region == "South")

# californica
californica_south <- milkweed_south %>%
  filter(scientific_name == "Asclepias californica")
# erosa
erosa_south <- milkweed_south %>%
  filter(scientific_name == "Asclepias erosa")
# eriocarpa
eriocarpa_south <- milkweed_south %>%
  filter(scientific_name == "Asclepias eriocarpa")
# vestita
vestita_south <- milkweed_south %>%
  filter(scientific_name == "Asclepias vestita")
```


## Model
To perform species distribution modeling, we have used various functions from the R packages {Wallace}, {dismo}, and {ENMeval}. There are many steps to the modeling process and these have been broken down into smaller sections


### Model South

#### Obtain environmental data values based on the occurence coordinates and join with the occurance points

Select species you want to model
```{r}
species_name <- "Asclepias eriocarpa"
```


```{r}
occurence_coordinates <- eriocarpa_south[c("longitude", "latitude")]
environmental_values <- as.data.frame(raster::extract(environmental_layers, occurence_coordinates, cellnumbers = TRUE))

# add columns for env variable values for each occurrence record
occurence_env_values <- cbind(eriocarpa_south, environmental_values)
```

#### Process the occurence and environmental data
```{r}
# Spatially thin the occurrence points
eriocarpa_south <- poccs_thinOccs(
  occs = occurence_env_values, 
  thinDist = 0.05) # adjust this value if you would like to change the thinning distaince (in km)


# Mask environmental data to provided extent
environmental_mask <- penvs_bgMask(
  occs = eriocarpa_south, # occurence points
  envs = environmental_layers, # environmental layers
  bgExt = lpnf_south_buffered) # extent to model on (southern section of lpnf with a buffer)

# Sample background points from the provided area
bg_sample_points <- penvs_bgSample(
  occs = eriocarpa_south, # occurence points
  bgMask =  environmental_mask, # environmental layers mask made above
  bgPtsNum = 5000) # number of points to be sampled from the area

# Extract values of environmental layers for each background point
bg_env_values <- as.data.frame(raster::extract(environmental_mask,  bg_sample_points))

#Add extracted values to background points table
bg_env_values <- cbind(scientific_name = paste0("bg_", species_name), bg_sample_points,
                            occID = NA, year = NA, institution_code = NA, country = NA,
                            state_province = NA, locality = NA, elevation = NA,
                            record_type = NA, bg_env_values)
```

#### Partition occurrence data

Partition occurrences and background points for model training and validation using block, a spatial partition method.

```{r}
# Partitioned data
partition_groups <- part_partitionOccs(
  occs = eriocarpa_south ,
  bg =  bg_sample_points, 
  method = "block") 
```

#### Build and Evaluate Model

We are using “Linear” (L) and “Linear Quadratic” (LQ) feature class settings (where L is more simple, i.e., canopy cover + temperature, and LQ is more complex, i.e., canopy cover^2^ + temperature^2^) and not using Hinge (piecewise linear functions) because the relationship that we are modeling is relatively simple. 

Regularization multipliers penalize model complexity, where higher values indicate smoother, less complex models. This is used to retain only the variables with the greatest predictive contribution in the model, thus performing feature selection. Regularization multipliers from 0.5 to 4 by increments of 0.5 are used, resulting in 16 models (L, LQ, x1 each per incremental increase). 

```{r}
# Run maxent model for the selected species
species_model <- model_maxent(
  occs = eriocarpa_south, 
  bg = bg_env_values,
  user.grp = partition_groups, 
  bgMsk = environmental_mask,
  rms = c(0.5, 4), 
  rmsStep =  0.5,
  fcs = c('L', 'LQ'),
  clampSel = FALSE,
  algMaxent = "maxnet",
  parallel = FALSE,
  numCores = 7)

# View table of model results
species_model@results %>%
  gt::gt()

# Select model and predict
auc_max_south <- species_model@results %>%
  select(tune.args, auc.train) %>%
  arrange(desc(auc.train)) %>%
  head(1) %>%
  mutate(tune.args = as.character(tune.args))

selected_model <- species_model@models[[auc_max_south$tune.args]] 

model_prediction <- predictMaxnet(selected_model, environmental_mask,
                                          type = "cloglog", # change for different types
                                          clamp = FALSE)
```

#### Model transfer (optional; only run if there is no North data)

```{r}
# Generate a transfer of the model to the desired area
xfer_area_mod <- xfer_area(
  evalOut = species_model,
  curModel = auc_max_south$tune.args,
  envs = environmental_layers, 
  outputType = "cloglog",
  alg = "maxnet",
  clamp = FALSE,
  xfExt = lpnf_north_buffered)

# store the cropped transfer variables
xfer_prediction <- xfer_area_mod$xferArea

# join the south model and north transfer model
joined_model <- merge(xfer_prediction, model_prediction) %>%
  rast() %>%
  crop(lpnf_boundary, mask = TRUE)
```

```{r}
## Plot everything together

# Get values of prediction
map_pred_values <- getRasterVals(joined_model, "cloglog") # change for different types

# Define colors and legend  
suitability_pal <- c("#FFFFFF", "#EFCCCC", "#DF9999", "#D06666", "#C03333", "#B00000")

legend_pal <- colorNumeric(suitability_pal, map_pred_values, na.color = 'transparent')
raster_pal <- colorNumeric(suitability_pal, map_pred_values, na.color = 'transparent')


leaflet() %>% 
  addProviderTiles(providers$Esri.WorldTopoMap) %>%
  addLegend_decreasing("bottomleft", pal = legend_pal, values = map_pred_values,
            labFormat = reverseLabel(), decreasing = TRUE,
            title = paste(species_name, "<br>Predicted Suitability<br>")) %>%
  addCircleMarkers(data = eriocarpa_points, lat = ~latitude, lng = ~longitude,
                   radius = 2, color = 'black', fill = TRUE, fillColor = "black",
                   fillOpacity = 0.2, weight = 2) %>% 
  ##Add model prediction
  addRasterImage(joined_model, colors = raster_pal, opacity = 0.7,
                 group = 'vis', layerId = 'mapPred', method = "ngb") %>%
  addPolygons(data = lpnf_boundary,
              fill = FALSE,
              color = "black",
              weight = 2)
```


### Model North


## Model Selection
```{r}
# select model and predict
auc_max_north <- model_Ac@results %>%
  select(tune.args, auc.train) %>%
  arrange(desc(auc.train)) %>%
  head(1) %>%
  mutate(tune.args = as.character(tune.args))
```

## Join models & Plot
- North and south data present
- South only and transfer

## Save model outputs





# Updating “closed” Trails and Roads
Direct to trails and roads doc that already has commented note on how to filter (note again that this is only applicable to the south)

### Using those updates to update site accessibility 
Instruct on where/how to run rescale layers, etc. again.

## Updating Site Priority 
Using new outputs from SDM – north and south, species-specific and max(all) 

Save outputs to _____ (note here that this is where the dashboard will be pulling from) 


